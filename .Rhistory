coef(logreg3)
coef(logreg3a)
logreg3 <- glm(usebin ~ factor(wind), family = "binomial", data = shuttle) #no intercept
logreg3a <- glm(I(1-usebin) ~ factor(wind), family = "binomial", data = shuttle) #no intercept
coef(logreg3)
coef(logreg3a)
data(mtcars)
str(mtcars)
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl) # Number of cylinders
mtcars$vs <- factor(mtcars$vs) # V/S
mtcars$am <- factor(mtcars$am,labels=c('automatic','manual')) # Transmission
mtcars$gear <- factor(mtcars$gear) # Number of forward gears
mtcars$carb <- factor(mtcars$carb) # Number of carburetors
str(mtcars)
pairs(mpg ~ ., data = mtcars)
pairs(mtcars, panel=panel.smooth, main="Pair Graph of Motor Trend Car Road Tests")
pairs(mpg ~ ., data = mtcars, panel=panel.smooth, main="Pair Plots of Motor Trend Car Road Tests")
fit <- lm(mpg ~ am, data = mtcars)
coef(summary(fit))
result <- t.test(mtcars$mpg ~ mtcars$am)
result$p.value
result$estimate
result$estimate[1]
result$estimate["automatic"]
result$estimate[0]
result$estimate[2]
fullmodel <- lm(mpg ~ ., data = mtcars)
bestmodel <- step(fullmodel, direction = "both")
summary(bestmodel)
fit <- lm(mpg ~ am, data = mtcars)
coef(summary(fit))
sumCoef<-summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
source('~/.active-rstudio-document', echo=TRUE)
summary(fit)
summary(fit)$resid
summary(fit)$rsquared
str(fit)
fit$qr
fit$coefficients
fit$df.residual
fit$effects
fit$fitted.values
fit$model
fit$adj.r.squared
plot(bestmodel)
dfbetas(bestmodel)
hatvalues(bestmodel)
summary(fit)$coefficients
summary(fit)$coefficients[1,1]
summary(fit)$coefficients[2,1]
summary(fit)$p.value
summary(fit)
summary(fit)$coefficients[2,]
summary(fit)$coefficients[2,4]
confint(fit)
confint(fit)[2,]
sumCoef[2,1]
sumCoef[1,1]
source('~/.active-rstudio-document', echo=TRUE)
x<-anova(fit,bestmodel)
x
str(x)
x$`Pr(>F)`
x$Pr
anova(fit, bestmodel)$Pr(>F)
anova(fit, bestmodel)$Pr
anova(fit, bestmodel)$Pr[3]
anova(fit, bestmodel)$Pr[4]
anova(fit, bestmodel)$Pr[1,2]
anova(fit, bestmodel)$Pr[1]
anova(fit, bestmodel)$Pr[2]
install.packages("caret")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(caret)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(test)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("Hmisc")
library("Hmisc", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=breaks))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=4))
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
View(training)
index <- seq_along(1:nrow(training))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Cement, g=4))
qplot(index, CompressiveStrength, data=training, color=cut2(training$BlastFurnaceSlag, g=4))
qplot(index, CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=4))
qplot(index, CompressiveStrength, data=training, color=cut2(training$Age, g=4))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
qplot(log(Superplasticizer+1), data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
preObj
preObj <- preProcess(training[, IL], method=c("center", "scale", "pca"), thresh=0.9)
preObj
IL <- grep("IL", names(training))
preObj <- preProcess(training[, IL], method=c("center", "scale", "pca"), thresh=0.9)
preObj
colnames(training)
IL <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL], method=c("center", "scale", "pca"), thresh=0.9)
preObj
IL <- grep("^IL", colnames(training))
PC <- preProcess(training[, IL], method=c("center", "scale", "pca"), thresh=0.9)
PC
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL <- grep("^IL", colnames(training))
IL_training <- training[,c("diagnosis",IL)]
View(training)
IL_training <- training[,c("diagnosis",colnames(training)[IL])]
modelFit <- train(diagnosis ~ ., method="glm", data=IL_training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Create a training data set consisting of only the predictors with variable
# names beginning with IL and the diagnosis. Build two predictive models, one
# using the predictors as they are and one using PCA with principal components
# explaining 80% of the variance in the predictors. Use method="glm" in the
# train function.
IL <- grep("^IL", colnames(training))
IL_training <- training[,c("diagnosis",colnames(training)[IL])]
modelFit <- train(diagnosis ~ ., method="glm", data=IL_training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
modelFit <- train(diagnosis ~ ., method="glm", data=IL_training)
trControl=trainControl(preProcOptions=list(thresh=0.8)))
modelFit <- train(training$diagnosis ~ ., method="glm", preProcess="pca",
data=IL_training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
install.packages("e1071")
modelFit <- train(diagnosis ~ ., method="glm", data=IL_training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
C1$overall[1]
modelFit <- train(training$diagnosis ~ ., method="glm", preProcess="pca",
data=IL_training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
C2$overall[1]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Find all the predictor variables in the training set that begin with IL.
# Perform principal components on these variables with the preProcess() function
# from the caret package. Calculate the number of principal components needed to
# capture 80% of the variance. How many are there?
IL <- grep("^IL", colnames(training))
PC <- preProcess(training[, IL], method=c("center", "scale", "pca"), thresh=0.8)
PC
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train <- segmentationOriginal[segmentationOriginal$Case =="Train",]
test <- segmentationOriginal[segmentationOriginal$Case =="Test",]
set.seed(125)
model <- train(Class~., data=training, method="rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# 1. Subset the data to a training set and testing set based on the Case
# variable in the data set.
#Case has values Train and Test
training <- segmentationOriginal[segmentationOriginal$Case =="Train",]
testing <- segmentationOriginal[segmentationOriginal$Case =="Test",]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
set.seed(125)
model <- train(Class~., data=training, method="rpart")
fancyRpartPlot(model$finalModel)
library(rpart)
fancyRpartPlot(model$finalModel)
library(rpart)
fancyRpartPlot(model$finalModel)
library(rattle)
install.packages("rattle")
fancyRpartPlot(model$finalModel)
library(rattle)
fancyRpartPlot(model$finalModel)
library(rattle)
fancyRpartPlot(model$finalModel)
install.packages("rattle")
install.packages("rattle")
install.packages("rattle")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# 1. Subset the data to a training set and testing set based on the Case
# variable in the data set.
#Case has values Train and Test
training <- segmentationOriginal[segmentationOriginal$Case =="Train",]
testing <- segmentationOriginal[segmentationOriginal$Case =="Test",]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
set.seed(125)
model <- train(Class~., data=training, method="rpart")
library(rpart)
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
# 1. Subset the data to a training set and testing set based on the Case
# variable in the data set.
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
set.seed(125)
model <- train(Class ~ ., data = training, method = "rpart")
model$finalModel
plot(model$finalModel, uniform=T)
text(model$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
data(olive)
olive = olive[,-1]
data(olive)
olive2 = olive[,-1]
olive = olive[,-1]
modFit<-train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata)
modFit<-train(Area ~ ., data=olive, method="rpart2")
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata) # [1] 2.783282
modFit<-train(Area ~ ., data=olive, method="rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata) # [1] 2.783282
View(olive2)
data(olive)
View(olive)
values(olive$Area)
summary(olive$Area)
olive$Area
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
# What is the misclassification rate on the training set? What is the
# misclassification rate on the test set?
missClass(testSA$chd, predict(model, newdata = testSA))
missClass(trainSA$chd, predict(model, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
library(caret)
model <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
library(caret)
model <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
model <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
modFit <- train(y ~ ., data = vowel.train, method="rf")
modFit <- train(y ~ ., data = vowel.train, method="rf")
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method="rf")
order(varImp(modFit), decreasing=T)
varImp(modFit)
modFit <- randomForest(y ~ ., data = vowel.train)
varImp(modFit)
modFit <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
varImp(modFit)
order(varImp(modFit), decreasing=T)
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
order(b, decreasing=T)
summary(modFit)
summary(modFit$importance)
modFit$importance
modFit$importanceSD
varimp(modFit)
varImp(modFit)
cls
clear
setwd("~/Coursera/practical-machine-learning/prediction-assignment-writeup")
setwd("~/Coursera/practical-machine-learning/prediction-assignment-writeup")
# The training data for this project are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileName <-"pml-training.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("training", mode = "list")){training <- read.csv(fileName, header = TRUE)}
# The test data are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
fileName <-"pml-testing.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("testing", mode = "list")){testing <- read.csv(fileName, header = TRUE)}
summary(training)
colnames(training)
colnames(testing)
str(training)
sum(is.na(testing))
trainingnona <-read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
trainingnona <-read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))
trainingnona <-read.csv("pml-training.csv", header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))
sum(is.na(training))
sum(is.na(trainingnona))
setwd("~/Coursera/practical-machine-learning/prediction-assignment-writeup")
# The training data for this project are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileName <-"pml-training.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("training", mode = "list")){
training <- read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
# The test data are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
fileName <-"pml-testing.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("testing", mode = "list")){
testing <- read.csv(ileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
testing <- read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
setwd("~/Coursera/practical-machine-learning/prediction-assignment-writeup")
# The training data for this project are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileName <-"pml-training.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("training", mode = "list")){
training <- read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
# The test data are available here:
fileUrl<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
fileName <-"pml-testing.csv"
if(!file.exists(fileName)){download.file(fileUrl, destfile = fileName, method = "curl")}
if(!exists("testing", mode = "list")){
testing <- read.csv(fileName, header = TRUE,
na.strings = c("", "NA", "NULL", "#DIV/0!"))}
str(training)
summary(training)
colSums(is.na(training))
colSums(is.na(training))>19000
sum(colSums(is.na(training))>19000)
sum(colSums(is.na(training))>1000)
sum(colSums(is.na(training))>19500)
sum(colSums(is.na(training))>19200)
sum(colSums(is.na(training))>0.9*length(training))
training <- training[,colSums(is.na(training))>0.9*length(training)]
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
training2 <- training[,!colSums(is.na(training))>0.9*length(training)]
sum(colSums(is.na(training2))>0.9*length(training))
sum(colSums(is.na(training))>0.9*length(training))
sum(colSums(is.na(training2))>0.9*length(training2))
colSums(is.na(training2))
colSums(is.na(training))
source('~/.active-rstudio-document', echo=TRUE)
raw3 <- raw2[,-(1:7)]
columns(raw3)
length(raw3)
sum(is.na(raw3))
sum(is.na(raw3[1]))
sum(is.na(raw))
sum(is.na(raw2))
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
ctrl <- trainControl(allowParallel=T, method="cv", number=4)
modFit <- train(classe ~ ., data=training, model="rf", trControl=ctrl)
pred <- predict(modFit, newdata=testing)
testing$predRight <- pred==testing$classe
table(pred,testing$classe)
sum(pred == testing$classe) / length(testing)
length(pred)
length(testing)
dim(testing)
sum(pred == testing$classe) / dim(testing)[1]
prediction <- predict(modFit, newdata=testcases)
prediction
modFit
out_of_sample_error <- 1 - accuracy
accuracy <- sum(pred == testing$classe) / length(pred)
accuracy #0.9928632
out_of_sample_error <- 1 - accuracy
out_of_sample_error
